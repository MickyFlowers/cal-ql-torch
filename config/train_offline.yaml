defaults:
  - cal_ql: cal_ql_defaults
  - logging: logging_defaults
  - dataset: dataset_defaults

observation_dim: 6
action_dim: 6


seed: 42
save_model: false
batch_size: 32
num_workers: 4


# Architecture & policy hyperparameters
hidden_dim: 256
orthogonal_init: true

policy_obs_proj_arch: '256-256-256-256'
policy_out_proj_arch: '256-256-256-256'
policy_log_std_multiplier: 1.0
policy_log_std_offset: -1.0
train_policy_backbone: true

q_obs_proj_arch: '256-256-256-256'
q_out_proj_arch: '256-256-256-256'
train_q_backbone: true
bc_start_epochs: 10
bc_transition_epochs: 10  # Number of epochs for BC->RL transition


# Offline pretraining / online finetuning schedule
train_offline_epochs: 100

# Learning rate scheduler
use_lr_scheduler: true
warmup_ratio: 0.05  # 5% of total steps for warmup
min_lr_ratio: 0.1   # decay to 10% of initial lr

# CQL related toggles
cql_min_q_weight: 0.5
torch_compile_mode: "max-autotune"

save_every_n_epoch: 100
ckpt_path: ./checkpoints
load_ckpt_path: ""
load_policy_ckpt_path: ""


discount: 0.999
device: cuda:0

freeze_policy_epochs: 50
