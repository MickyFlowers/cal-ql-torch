defaults:
  - logging: logging_defaults
  - dataset: dataset_defaults

device: cuda:0
batch_size: 16
num_workers: 4
action_dim: 6
pred_horizon: 15
img_token_dim: 1024
state_token_dim: 12
img_cond_len: 256
img_pos_embed_config: null
model_name: vit_tiny_patch16_224
trainable_layers: ["block.10", "block.11", "norm"]
dp_config:
  depth: 4
  num_heads: 8
  hidden_size: 256
  img_adaptor: mlp2x_gelu
  state_adaptor: mlp3x_gelu
  noise_scheduler:
    type: ddpm
    num_train_timesteps: 1000
    num_inference_timesteps: 5
    beta_schedule: squaredcos_cap_v2 
    prediction_type: sample
    clip_sample: False
  ema:
    update_after_step: 0
    inv_gamma: 1.0
    power: 0.75
    min_value: 0.0
    max_value: 0.9999
  
trainer: 
  learning_rate: 1e-4
  weight_decay: 0.01
  betas: [0.9, 0.999]
  adam_epsilon: 1e-8

  lr_scheduler: constant
  warmup_steps: 500
  lr_num_cycles: 1
  max_epochs: {max_epochs}
  num_cycles: 1
  power: 1.0

max_epochs: 1000
seed: 42
eval_every_n_epochs: 10
load_ckpt_path: ""
ckpt_path: "./checkpoints"
save_every_n_epoch: 50

